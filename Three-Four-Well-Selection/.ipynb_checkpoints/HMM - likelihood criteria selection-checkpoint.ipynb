{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert_arbon/anaconda/envs/sonification/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/robert_arbon/anaconda/envs/sonification/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/robert_arbon/anaconda/envs/sonification/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from pyemma.msm import MaximumLikelihoodMSM, BayesianMSM, MaximumLikelihoodHMSM, its\n",
    "from bhmm import lag_observations\n",
    "import pyemma.plots as mplt\n",
    "import pyemma.coordinates as coor\n",
    "from msmbuilder.cluster import NDGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bic(hmm):\n",
    "    p = dof(hmm)\n",
    "    ndata = n_obs(hmm)\n",
    "    loglike = hmm.likelihood # log likelihood\n",
    "    return np.log(ndata)*p - 2*loglike\n",
    "\n",
    "def icl(hmm):\n",
    "    return 2*class_entropy(hmm) + bic(hmm)\n",
    "\n",
    "def class_entropy(hmm):\n",
    "    h_probs = hmm.hidden_state_probabilities\n",
    "    ent = np.sum([np.sum(entropy(x.T)) for x in h_probs])\n",
    "    return ent\n",
    "\n",
    "def aic(hmm):\n",
    "    p = dof(hmm)\n",
    "    loglike = hmm.likelihood # log likelihood    \n",
    "    return 2*p - 2*loglike\n",
    "\n",
    "def n_obs(hmm):\n",
    "    nobs = np.sum([x.shape[0] for x in hmm.dtrajs_obs])\n",
    "    return nobs\n",
    "    \n",
    "def dof(hmm):\n",
    "    N = hmm.metastable_distributions.shape[0] # Num hidden states\n",
    "    M = hmm.metastable_distributions.shape[1] # Num observed states\n",
    "    \n",
    "    # Shouldn't be needed - need to check. \n",
    "#     assert hmm.count_matrix.shape[0] == N, \"\"\n",
    "    \n",
    "    dof = N*(M-1) # Emission probabilities add to one.\n",
    "    if hmm.reversible:\n",
    "        dof += (1/2)*N*(N-1) + N - 1\n",
    "    else:\n",
    "        dof += N*(N-1)\n",
    "\n",
    "    dof = int(dof)\n",
    "\n",
    "#     or hmm.observe_nonempty  - don't need this (I think)\n",
    "\n",
    "    if (hmm.separate is not None) or (hmm.connectivity is None) or \\\n",
    "        hmm.connectivity=='all':\n",
    "        print(hmm.separate)\n",
    "        print(hmm.connectivity)\n",
    "        print(\"BIC/AIC not available for these constraints\")\n",
    "        return None\n",
    "    else:\n",
    "        return dof\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'four-well-long'\n",
    "X = [np.load(x) for x in glob('data/'+data_name+'/*npy')]\n",
    "# X = [y for x in X for y in np.array_split(x,8)]\n",
    "xmin = np.min(np.concatenate(X))\n",
    "xmax = np.max(np.concatenate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.08975021948 1.10160887266\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "m_opt = 200 #(200,int(np.sqrt(len(X)*X[0].shape[0])))\n",
    "# numFrames = np.sum([x.shape[0] for x in X])\n",
    "# m_opt = int(max(np.round(0.6 * np.log10(numFrames / 1000) * 1000 + 50), 100)) \n",
    "print(xmin, xmax)\n",
    "print(m_opt)\n",
    "cluster = NDGrid(min=xmin, max=xmax, n_bins_per_feature=m_opt)\n",
    "dtrajs = cluster.fit_transform(X)\n",
    "# dtrajs = cluster.dtrajs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose taus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.load('timescales.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[844, 125, 64, 11, 6, 4]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group timescales that differ by less than one: \n",
    "grouped_ts = []\n",
    "i = 0\n",
    "\n",
    "while i < len(ts)-1:\n",
    "    if np.abs(ts[i+1]-ts[i]) < 2:\n",
    "        grouped_ts.append(int(np.mean(ts[i:i+2])))\n",
    "        i +=2\n",
    "    else:\n",
    "        grouped_ts.append(int(ts[i]))\n",
    "        i += 1\n",
    "grouped_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[484, 94, 37, 8, 5]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taus = [int((grouped_ts[i]+grouped_ts[i+1])/2) for i in range(len(grouped_ts)-1)]\n",
    "taus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ergodic set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n",
      "0.9999940793368858\n",
      "0.99\n"
     ]
    }
   ],
   "source": [
    "print(taus[0])\n",
    "m = MaximumLikelihoodMSM(lag=taus[0], connectivity='largest', reversible=True )\n",
    "m.fit(dtrajs)\n",
    "print(m.active_count_fraction)\n",
    "print(m.active_state_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erg_dtrajs = [x for x in m.dtrajs_active if not -1 in x]\n",
    "len(erg_dtrajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "m = MaximumLikelihoodMSM(lag=taus[0], connectivity='largest', reversible=True )\n",
    "m.fit(erg_dtrajs)\n",
    "print(m.active_count_fraction)\n",
    "print(m.active_state_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden state selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n",
      "2\n",
      "Fitting HMM\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-dd9ce67882d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         hmm = MaximumLikelihoodHMSM(nstates=int(k), lag=tau, stationary=False, reversible=True, connectivity='largest',\n\u001b[1;32m     17\u001b[0m                                    msm_init=m)\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merg_dtrajs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tau'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/sonification/lib/python3.5/site-packages/pyemma/_base/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \"\"\"\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/sonification/lib/python3.5/site-packages/pyemma/_base/estimator.py\u001b[0m in \u001b[0;36mestimate\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/sonification/lib/python3.5/site-packages/pyemma/msm/estimators/maximum_likelihood_hmsm.py\u001b[0m in \u001b[0;36m_estimate\u001b[0;34m(self, dtrajs)\u001b[0m\n\u001b[1;32m    233\u001b[0m                                               accuracy=self.accuracy, maxit=self.maxit)\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mhmm_est\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;31m# package in discrete HMM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbhmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscreteHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm_est\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/sonification/lib/python3.5/site-packages/bhmm/estimators/maximum_likelihood.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mloglik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                 \u001b[0mloglik\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/sonification/lib/python3.5/site-packages/bhmm/estimators/maximum_likelihood.py\u001b[0m in \u001b[0;36m_forward_backward\u001b[0;34m(self, itraj)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# self._fbtimings[1] += t3-t2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# backward variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;31m# t4 = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# self._fbtimings[2] += t4-t3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/sonification/lib/python3.5/site-packages/bhmm/hidden/api.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(A, pobs, T, beta_out)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m__impl__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m__IMPL_C__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Nonexisting implementation selected: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__impl__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ks = np.arange(2,10)\n",
    "results = {'tau': [], 'k': [], 'bic': [], 'aic': [], 'icl': [], 'entropy': [], 'n_obs': [], 'dofs': []}\n",
    "for tau in taus:\n",
    "    \n",
    "    print(tau)\n",
    "    \n",
    "    for k in ks:\n",
    "        \n",
    "        print(k)\n",
    "        \n",
    "        m = MaximumLikelihoodMSM(lag=tau, connectivity='largest', reversible=True )\n",
    "        m.fit(erg_dtrajs)\n",
    "        \n",
    "        assert m.active_count_fraction == 1.0, 'Active count fraction not 1.0'\n",
    "        print('Fitting HMM')\n",
    "        hmm = MaximumLikelihoodHMSM(nstates=int(k), lag=tau, stationary=False, reversible=True, connectivity='largest',\n",
    "                                   msm_init=m)\n",
    "        hmm.fit(erg_dtrajs)\n",
    "        results['k'].append(k)\n",
    "        results['tau'].append(tau)\n",
    "        results['bic'].append(bic(hmm))\n",
    "        results['aic'].append(aic(hmm))\n",
    "        results['icl'].append(icl(hmm))\n",
    "        results['entropy'].append(class_entropy(hmm))\n",
    "        results['dofs'].append(dof(hmm))\n",
    "        results['n_obs'].append(n_obs(hmm))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aic</th>\n",
       "      <th>bic</th>\n",
       "      <th>dofs</th>\n",
       "      <th>entropy</th>\n",
       "      <th>icl</th>\n",
       "      <th>k</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.425876e+06</td>\n",
       "      <td>1.429506e+06</td>\n",
       "      <td>362</td>\n",
       "      <td>178.975093</td>\n",
       "      <td>1.429864e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>167211</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.342852e+06</td>\n",
       "      <td>1.348317e+06</td>\n",
       "      <td>545</td>\n",
       "      <td>1085.692767</td>\n",
       "      <td>1.350488e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>167211</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.253645e+06</td>\n",
       "      <td>1.260955e+06</td>\n",
       "      <td>729</td>\n",
       "      <td>4280.968618</td>\n",
       "      <td>1.269517e+06</td>\n",
       "      <td>4</td>\n",
       "      <td>167211</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.229424e+06</td>\n",
       "      <td>1.238589e+06</td>\n",
       "      <td>914</td>\n",
       "      <td>12050.737803</td>\n",
       "      <td>1.262690e+06</td>\n",
       "      <td>5</td>\n",
       "      <td>167211</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.217024e+06</td>\n",
       "      <td>1.228054e+06</td>\n",
       "      <td>1100</td>\n",
       "      <td>15552.359472</td>\n",
       "      <td>1.259159e+06</td>\n",
       "      <td>6</td>\n",
       "      <td>167211</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.201568e+06</td>\n",
       "      <td>1.214473e+06</td>\n",
       "      <td>1287</td>\n",
       "      <td>22122.119122</td>\n",
       "      <td>1.258717e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>167211</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            aic           bic  dofs       entropy           icl  k   n_obs  \\\n",
       "0  1.425876e+06  1.429506e+06   362    178.975093  1.429864e+06  2  167211   \n",
       "1  1.342852e+06  1.348317e+06   545   1085.692767  1.350488e+06  3  167211   \n",
       "2  1.253645e+06  1.260955e+06   729   4280.968618  1.269517e+06  4  167211   \n",
       "3  1.229424e+06  1.238589e+06   914  12050.737803  1.262690e+06  5  167211   \n",
       "4  1.217024e+06  1.228054e+06  1100  15552.359472  1.259159e+06  6  167211   \n",
       "5  1.201568e+06  1.214473e+06  1287  22122.119122  1.258717e+06  7  167211   \n",
       "\n",
       "   tau  \n",
       "0    5  \n",
       "1    5  \n",
       "2    5  \n",
       "3    5  \n",
       "4    5  \n",
       "5    5  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(results, open('h_state_selection.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df = pd.melt(frame=df, id_vars='k', value_name='score', var_name='criterion')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_scores = df.groupby('criterion')['score'].transform('min')\n",
    "idx = df['score'] == min_scores\n",
    "best = df.loc[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = df['criterion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context('paper', font_scale=1.5):\n",
    "    sns.set_style('whitegrid')\n",
    "    g = sns.FacetGrid(data=df, col='criterion', col_order=criteria)\n",
    "    g.map(plt.scatter, 'k', 'score')\n",
    "    for i, ax in enumerate(g.axes.flatten()):\n",
    "        idx = best['criterion']==criteria[i]\n",
    "        ax.scatter(best.loc[idx, 'k'],best.loc[idx, 'score'] , marker='o',s=50, color='k')\n",
    "    # g.set(yscale='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MaximumLikelihoodMSM(lag=tau, connectivity='largest', reversible=True )\n",
    "m.fit(dtrajs)\n",
    "hmm = MaximumLikelihoodHMSM(nstates=int(6), lag=tau, stationary=False, reversible=True, connectivity='largest', \n",
    "                           msm_init=m)\n",
    "hmm.fit(dtrajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context('paper', font_scale=1):\n",
    "    fig, axes = plt.subplots(6, sharex=True)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(hmm.metastable_distributions[ i,:]*25)\n",
    "        ax.plot(hmm.stationary_distribution_obs*100)\n",
    "        ax.set_ylabel('State {}'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context('paper', font_scale=1):\n",
    "    fig, axes = plt.subplots(6, sharex=True, sharey=True, figsize=(6,8))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(m.eigenvectors_right()[:,i+1])\n",
    "        ax.plot(m.pi*100)\n",
    "        ax.set_ylabel('State {}'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm.lifetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mplt.plot_markov_model(P=hmm.P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse graining - fixed n_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=4\n",
    "hmm = msm.coarse_grain(ncoarse=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array2string(hmm.P*100, formatter={'float_kind':lambda x: \"%.2f\" % x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ck = hmm.cktest(err_est=False, mlags=10, show_progress=False)\n",
    "_ = mplt.plot_cktest(ck, diag=True, figsize=(7,7), layout=(2,2), padding_top=0.1, y01=False, padding_between=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context('paper', font_scale=1):\n",
    "    fig, axes = plt.subplots(n, sharex=True)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(hmm.metastable_memberships[:, i])\n",
    "        ax.plot(hmm.stationary_distribution_obs*100)\n",
    "        ax.set_ylabel('State {}'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(A, pobs, pi, T=None, alpha_out=None, dtype=np.float32):\n",
    "    \"\"\"Compute P( obs | A, B, pi ) and all forward coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray((N,N), dtype = float)\n",
    "        transition matrix of the hidden states\n",
    "    pobs : ndarray((T,N), dtype = float)\n",
    "        pobs[t,i] is the observation probability for observation at time t given hidden state i\n",
    "    pi : ndarray((N), dtype = float)\n",
    "        initial distribution of hidden states\n",
    "    T : int, optional, default = None\n",
    "        trajectory length. If not given, T = pobs.shape[0] will be used.\n",
    "    alpha_out : ndarray((T,N), dtype = float), optional, default = None\n",
    "        container for the alpha result variables. If None, a new container will be created.\n",
    "    dtype : type, optional, default = np.float32\n",
    "        data type of the result.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logprob : float\n",
    "        The probability to observe the sequence `ob` with the model given\n",
    "        by `A`, `B` and `pi`.\n",
    "    alpha : ndarray((T,N), dtype = float), optional, default = None\n",
    "        alpha[t,i] is the ith forward coefficient of time t. These can be\n",
    "        used in many different algorithms related to HMMs.\n",
    "\n",
    "    \"\"\"\n",
    "#     from decimal import Decimal as dec\n",
    "    \n",
    "    # set T\n",
    "    if T is None:\n",
    "        T = pobs.shape[0]  # if not set, use the length of pobs as trajectory length\n",
    "    elif T > pobs.shape[0]:\n",
    "        raise ValueError('T must be at most the length of pobs.')\n",
    "    # set N\n",
    "    N = A.shape[0]\n",
    "    # initialize output if necessary\n",
    "    if alpha_out is None:\n",
    "        alpha_out = np.zeros((T, N), dtype=dtype)\n",
    "    elif T > alpha_out.shape[0]:\n",
    "        raise ValueError('alpha_out must at least have length T in order to fit trajectory.')\n",
    "    # log-likelihood\n",
    "#     logprob = dec(0.0)\n",
    "    logprob = 0.0\n",
    "\n",
    "    # initial values\n",
    "    # alpha_i(0) = pi_i * B_i,ob[0]\n",
    "    np.multiply(pi, pobs[0, :], out=alpha_out[0])\n",
    "\n",
    "    # scaling factor\n",
    "    scale = np.sum(alpha_out[0, :])\n",
    "    # scale\n",
    "    alpha_out[0, :] /= scale\n",
    "#     logprob += dec(float(np.log(scale)))\n",
    "    logprob += np.log(scale)\n",
    "    \n",
    "    # induction\n",
    "    for t in range(T-1):\n",
    "        # alpha_j(t+1) = sum_i alpha_i(t) * A_i,j * B_j,ob(t+1)\n",
    "        np.multiply(np.dot(alpha_out[t, :], A), pobs[t+1, :], out=alpha_out[t+1])\n",
    "        # scaling factor\n",
    "        scale = np.sum(alpha_out[t+1, :])\n",
    "        # scale\n",
    "        alpha_out[t+1, :] /= scale\n",
    "\n",
    "        # update logprob\n",
    "#         logprob += dec(float(np.log(scale)))\n",
    "        logprob += np.log(scale)\n",
    "\n",
    "\n",
    "    return logprob, alpha_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.arange(4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'k': [], 'll': [], 'fold': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for kdx, k in enumerate(ks):\n",
    "    print(k)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(dtrajs)):\n",
    "        train = [dtrajs[i] for i in train_idx]\n",
    "        test = [dtrajs[i] for i in test_idx]\n",
    "        print('\\t', idx)\n",
    "        # initialize MInit\n",
    "        Minit = MaximumLikelihoodMSM(lag=tau)\n",
    "        Minit.fit(train)\n",
    "\n",
    "        # Map new trajectories\n",
    "        ttrain = Minit.dtrajs_active\n",
    "        ttest = []\n",
    "        for x in test:\n",
    "            try:\n",
    "                ttest.append(Minit._full2active[x])\n",
    "            except:\n",
    "                pass\n",
    "        ttest_lagged = lag_observations(ttest, lag=tau, stride=10)\n",
    "        print(len(ttest_lagged))\n",
    "        \n",
    "        # Fit HMM\n",
    "        M = MaximumLikelihoodHMSM(lag=tau, nstates=k, msm_init=Minit)\n",
    "        M.fit(train)\n",
    "        \n",
    "        # get parameters\n",
    "        obs_prob = M.observation_probabilities\n",
    "        T = M.transition_matrix\n",
    "        p0 = M.initial_distribution\n",
    "\n",
    "        # Get log likelihood \n",
    "        loglik = 0\n",
    "        for obs in ttest_lagged:\n",
    "            p_obs = obs_prob[:, obs].T\n",
    "            loglik += forward(T, p_obs, p0, dtype=np.longdouble)[0]\n",
    "        results['ll'].append(loglik)\n",
    "        results['k'].append(k)\n",
    "        results['fold'].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {'k': [], 'll': [], 'fold': []}\n",
    "# ks = np.arange(2,5)\n",
    "\n",
    "\n",
    "# for kdx, k in enumerate(ks):\n",
    "#     print(k)\n",
    "#     for idx, (train_idx, test_idx) in enumerate(cv.split(dtrajs)):\n",
    "#         train = [dtrajs[i] for i in train_idx]\n",
    "#         test = [dtrajs[i] for i in test_idx]\n",
    "#         print('\\t', idx)\n",
    "\n",
    "#         # Fit HMM\n",
    "#         M = MaximumLikelihoodHMSM(lag=tau, nstates=k)\n",
    "#         M.fit(train)\n",
    "        \n",
    "#         # Map new trajectories\n",
    "#         ttest = []\n",
    "#         for x in test:\n",
    "#             try:\n",
    "#                 ttest.append(M._full2active[x])\n",
    "#             except:\n",
    "#                 pass\n",
    "#         ttest_lagged = lag_observations(ttest, lag=tau)\n",
    "    \n",
    "        \n",
    "#         # get parameters\n",
    "#         obs_prob = M.observation_probabilities\n",
    "#         T = M.transition_matrix\n",
    "#         p0 = M.initial_distribution\n",
    "\n",
    "#         # Get log likelihood \n",
    "#         loglik = 0\n",
    "#         for obs in ttest_lagged:\n",
    "#             p_obs = obs_prob[:, obs].T\n",
    "#             loglik += forward(T, p_obs, p0, dtype=np.longdouble)[0]\n",
    "#         results['ll'].append(loglik)\n",
    "#         results['k'].append(k)\n",
    "#         results['fold'].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='k', y='ll', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(ks, -df.groupby(['k']).aggregate(np.median)['ll'], width=0.5)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=df, hue='k')\n",
    "g.map(sns.distplot, 'll', rug=True, hist=False).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
