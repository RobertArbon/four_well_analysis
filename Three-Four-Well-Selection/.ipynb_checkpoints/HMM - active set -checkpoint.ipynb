{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert_arbon/anaconda/envs/sonification/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/robert_arbon/anaconda/envs/sonification/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/robert_arbon/anaconda/envs/sonification/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from pyemma.msm import MaximumLikelihoodMSM, BayesianMSM, MaximumLikelihoodHMSM, its\n",
    "from bhmm import lag_observations\n",
    "import pyemma.plots as mplt\n",
    "from msmbuilder.cluster import NDGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = -1.2, 1.2\n",
    "tau = 8\n",
    "data_name = 'four-well'\n",
    "n = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(845, 1)\n"
     ]
    }
   ],
   "source": [
    "X = [np.load(x) for x in glob('data/'+data_name+'/*npy')]\n",
    "# X = [y for x in X for y in np.array_split(x,8)]\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "m_opt = min(200,int(np.sqrt(len(X)*X[0].shape[0])))\n",
    "print(m_opt)\n",
    "cluster = NDGrid(min=xmin, max=xmax, n_bins_per_feature=m_opt)\n",
    "dtrajs = cluster.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaximumLikelihoodMSM(connectivity='largest', count_mode='sliding',\n",
       "           dt_traj='1 step', lag=8, maxerr=1e-08, maxiter=1000000,\n",
       "           mincount_connectivity='1/n', reversible=True, score_k=10,\n",
       "           score_method='VAMP2', sparse=False, statdist_constraint=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MaximumLikelihoodMSM(lag=tau, connectivity='largest', reversible=True )\n",
    "m.fit(dtrajs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "91.0\n",
      "1.0\n",
      "0.9479166666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  8,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,\n",
       "        23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
       "        36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n",
       "        49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n",
       "        62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
       "        75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
       "       101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "       114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "       127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
       "       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "       166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
       "       179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(m.active_set))\n",
    "print(len(m.active_set)/m_opt*100)\n",
    "print(m.active_count_fraction)\n",
    "print(m.active_state_fraction)\n",
    "m.active_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m.active_set)/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajs = lag_observations([np.arange(50)], lag=8)\n",
    "np.sum([x.shape[0]-1 for x in trajs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84500"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(o) for o in dtrajs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lagged_h_probs = [lag_observations(observations=x, lag=8, stride=1) for x in sub_hmm.hidden_state_probabilities]\n",
    "\n",
    "lagged_h_probs\n",
    "# n_obs = np.sum([x.shape[0] for x in lagged_h_probs])\n",
    "# n_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83700"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(np.sum(sub_hmm.count_matrix)) # Number of data points\n",
    "n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dofs - n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 189\n"
     ]
    }
   ],
   "source": [
    "N = hmm.metastable_distributions.shape[0] # Num hidden states\n",
    "M = hmm.metastable_distributions.shape[1]\n",
    "print(N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dof, _ = dof(hmm)\n",
    "total_dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/2)*N*(N-1) + N - 1 + N*(M-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icl(hmm, tau=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden state selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "ks = np.arange(2,8)\n",
    "tau = 8\n",
    "results = {'k': [], 'bic': [], 'aic': [], 'icl': []}\n",
    "for k in ks:\n",
    "    print(k)\n",
    "#     m = MaximumLikelihoodMSM(lag=tau, connectivity='largest', reversible=True )\n",
    "#     m.fit(dtrajs)\n",
    "    hmm = MaximumLikelihoodHMSM(nstates=int(k), lag=tau, stationary=False, reversible=True, connectivity='largest',) \n",
    "#                                msm_init=m)\n",
    "    hmm.fit(dtrajs)\n",
    "#     hmm = m.coarse_grain(k, method=)\n",
    "    results['k'].append(k)\n",
    "    results['bic'].append(bic(hmm))\n",
    "    results['aic'].append(aic(hmm))\n",
    "    results['icl'].append(icl(hmm, tau))\n",
    "#     results['entropy'].append(class_entropy(hmm))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df = pd.melt(frame=df, id_vars='k', value_name='score', var_name='criterion')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_scores = df.groupby('criterion')['score'].transform('min')\n",
    "idx = df['score'] == min_scores\n",
    "best = df.loc[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = df['criterion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAADHCAYAAAB7n3U+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ6LiTkRERMSJqLgTERERcSL/HyWX1canjQtxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116e7cef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with sns.plotting_context('paper', font_scale=1.5):\n",
    "    sns.set_style('whitegrid')\n",
    "    g = sns.FacetGrid(data=df, col='criterion', col_order=criteria)\n",
    "    g.map(plt.scatter, 'k', 'score')\n",
    "    for i, ax in enumerate(g.axes.flatten()):\n",
    "        idx = best['criterion']==criteria[i]\n",
    "        ax.scatter(best.loc[idx, 'k'],best.loc[idx, 'score'] , marker='o',s=50, color='k')\n",
    "    # g.set(yscale='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MaximumLikelihoodMSM(lag=tau, connectivity='largest', reversible=True )\n",
    "m.fit(dtrajs)\n",
    "hmm = MaximumLikelihoodHMSM(nstates=int(6), lag=tau, stationary=False, reversible=True, connectivity='largest', \n",
    "                           msm_init=m)\n",
    "hmm.fit(dtrajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context('paper', font_scale=1):\n",
    "    fig, axes = plt.subplots(6, sharex=True)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(hmm.metastable_distributions[ i,:]*25)\n",
    "        ax.plot(hmm.stationary_distribution_obs*100)\n",
    "        ax.set_ylabel('State {}'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context('paper', font_scale=1):\n",
    "    fig, axes = plt.subplots(6, sharex=True, sharey=True, figsize=(6,8))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(m.eigenvectors_right()[:,i+1])\n",
    "        ax.plot(m.pi*100)\n",
    "        ax.set_ylabel('State {}'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm.lifetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mplt.plot_markov_model(P=hmm.P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse graining - fixed n_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=4\n",
    "hmm = msm.coarse_grain(ncoarse=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array2string(hmm.P*100, formatter={'float_kind':lambda x: \"%.2f\" % x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ck = hmm.cktest(err_est=False, mlags=10, show_progress=False)\n",
    "_ = mplt.plot_cktest(ck, diag=True, figsize=(7,7), layout=(2,2), padding_top=0.1, y01=False, padding_between=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context('paper', font_scale=1):\n",
    "    fig, axes = plt.subplots(n, sharex=True)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(hmm.metastable_memberships[:, i])\n",
    "        ax.plot(hmm.stationary_distribution_obs*100)\n",
    "        ax.set_ylabel('State {}'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(A, pobs, pi, T=None, alpha_out=None, dtype=np.float32):\n",
    "    \"\"\"Compute P( obs | A, B, pi ) and all forward coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray((N,N), dtype = float)\n",
    "        transition matrix of the hidden states\n",
    "    pobs : ndarray((T,N), dtype = float)\n",
    "        pobs[t,i] is the observation probability for observation at time t given hidden state i\n",
    "    pi : ndarray((N), dtype = float)\n",
    "        initial distribution of hidden states\n",
    "    T : int, optional, default = None\n",
    "        trajectory length. If not given, T = pobs.shape[0] will be used.\n",
    "    alpha_out : ndarray((T,N), dtype = float), optional, default = None\n",
    "        container for the alpha result variables. If None, a new container will be created.\n",
    "    dtype : type, optional, default = np.float32\n",
    "        data type of the result.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logprob : float\n",
    "        The probability to observe the sequence `ob` with the model given\n",
    "        by `A`, `B` and `pi`.\n",
    "    alpha : ndarray((T,N), dtype = float), optional, default = None\n",
    "        alpha[t,i] is the ith forward coefficient of time t. These can be\n",
    "        used in many different algorithms related to HMMs.\n",
    "\n",
    "    \"\"\"\n",
    "#     from decimal import Decimal as dec\n",
    "    \n",
    "    # set T\n",
    "    if T is None:\n",
    "        T = pobs.shape[0]  # if not set, use the length of pobs as trajectory length\n",
    "    elif T > pobs.shape[0]:\n",
    "        raise ValueError('T must be at most the length of pobs.')\n",
    "    # set N\n",
    "    N = A.shape[0]\n",
    "    # initialize output if necessary\n",
    "    if alpha_out is None:\n",
    "        alpha_out = np.zeros((T, N), dtype=dtype)\n",
    "    elif T > alpha_out.shape[0]:\n",
    "        raise ValueError('alpha_out must at least have length T in order to fit trajectory.')\n",
    "    # log-likelihood\n",
    "#     logprob = dec(0.0)\n",
    "    logprob = 0.0\n",
    "\n",
    "    # initial values\n",
    "    # alpha_i(0) = pi_i * B_i,ob[0]\n",
    "    np.multiply(pi, pobs[0, :], out=alpha_out[0])\n",
    "\n",
    "    # scaling factor\n",
    "    scale = np.sum(alpha_out[0, :])\n",
    "    # scale\n",
    "    alpha_out[0, :] /= scale\n",
    "#     logprob += dec(float(np.log(scale)))\n",
    "    logprob += np.log(scale)\n",
    "    \n",
    "    # induction\n",
    "    for t in range(T-1):\n",
    "        # alpha_j(t+1) = sum_i alpha_i(t) * A_i,j * B_j,ob(t+1)\n",
    "        np.multiply(np.dot(alpha_out[t, :], A), pobs[t+1, :], out=alpha_out[t+1])\n",
    "        # scaling factor\n",
    "        scale = np.sum(alpha_out[t+1, :])\n",
    "        # scale\n",
    "        alpha_out[t+1, :] /= scale\n",
    "\n",
    "        # update logprob\n",
    "#         logprob += dec(float(np.log(scale)))\n",
    "        logprob += np.log(scale)\n",
    "\n",
    "\n",
    "    return logprob, alpha_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.arange(4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'k': [], 'll': [], 'fold': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for kdx, k in enumerate(ks):\n",
    "    print(k)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(dtrajs)):\n",
    "        train = [dtrajs[i] for i in train_idx]\n",
    "        test = [dtrajs[i] for i in test_idx]\n",
    "        print('\\t', idx)\n",
    "        # initialize MInit\n",
    "        Minit = MaximumLikelihoodMSM(lag=tau)\n",
    "        Minit.fit(train)\n",
    "\n",
    "        # Map new trajectories\n",
    "        ttrain = Minit.dtrajs_active\n",
    "        ttest = []\n",
    "        for x in test:\n",
    "            try:\n",
    "                ttest.append(Minit._full2active[x])\n",
    "            except:\n",
    "                pass\n",
    "        ttest_lagged = lag_observations(ttest, lag=tau, stride=10)\n",
    "        print(len(ttest_lagged))\n",
    "        \n",
    "        # Fit HMM\n",
    "        M = MaximumLikelihoodHMSM(lag=tau, nstates=k, msm_init=Minit)\n",
    "        M.fit(train)\n",
    "        \n",
    "        # get parameters\n",
    "        obs_prob = M.observation_probabilities\n",
    "        T = M.transition_matrix\n",
    "        p0 = M.initial_distribution\n",
    "\n",
    "        # Get log likelihood \n",
    "        loglik = 0\n",
    "        for obs in ttest_lagged:\n",
    "            p_obs = obs_prob[:, obs].T\n",
    "            loglik += forward(T, p_obs, p0, dtype=np.longdouble)[0]\n",
    "        results['ll'].append(loglik)\n",
    "        results['k'].append(k)\n",
    "        results['fold'].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {'k': [], 'll': [], 'fold': []}\n",
    "# ks = np.arange(2,5)\n",
    "\n",
    "\n",
    "# for kdx, k in enumerate(ks):\n",
    "#     print(k)\n",
    "#     for idx, (train_idx, test_idx) in enumerate(cv.split(dtrajs)):\n",
    "#         train = [dtrajs[i] for i in train_idx]\n",
    "#         test = [dtrajs[i] for i in test_idx]\n",
    "#         print('\\t', idx)\n",
    "\n",
    "#         # Fit HMM\n",
    "#         M = MaximumLikelihoodHMSM(lag=tau, nstates=k)\n",
    "#         M.fit(train)\n",
    "        \n",
    "#         # Map new trajectories\n",
    "#         ttest = []\n",
    "#         for x in test:\n",
    "#             try:\n",
    "#                 ttest.append(M._full2active[x])\n",
    "#             except:\n",
    "#                 pass\n",
    "#         ttest_lagged = lag_observations(ttest, lag=tau)\n",
    "    \n",
    "        \n",
    "#         # get parameters\n",
    "#         obs_prob = M.observation_probabilities\n",
    "#         T = M.transition_matrix\n",
    "#         p0 = M.initial_distribution\n",
    "\n",
    "#         # Get log likelihood \n",
    "#         loglik = 0\n",
    "#         for obs in ttest_lagged:\n",
    "#             p_obs = obs_prob[:, obs].T\n",
    "#             loglik += forward(T, p_obs, p0, dtype=np.longdouble)[0]\n",
    "#         results['ll'].append(loglik)\n",
    "#         results['k'].append(k)\n",
    "#         results['fold'].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='k', y='ll', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(ks, -df.groupby(['k']).aggregate(np.median)['ll'], width=0.5)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=df, hue='k')\n",
    "g.map(sns.distplot, 'll', rug=True, hist=False).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
